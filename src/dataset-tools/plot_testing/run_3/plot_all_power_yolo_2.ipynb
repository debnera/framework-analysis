{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from pandas.core.interchange.dataframe_protocol import DataFrame\n",
    "\n",
    "\n",
    "# Function to find the subfolders with the file names\n",
    "def find_subfolders_with_file(root_folder, filename):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        if filename in files:\n",
    "            result.append(root)\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "root_folder = '../../../data/minimized'\n",
    "filename = 'worker1.feather'\n",
    "subfolders = find_subfolders_with_file(root_folder, filename)\n",
    "print(subfolders)"
   ],
   "id": "6a5183090ba2659d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def read_feather_cached(file_path):\n",
    "    return pd.read_feather(file_path)"
   ],
   "id": "ad90a1f2475eed8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "from utils.header_cleaner import *\n",
    "import difflib\n",
    "import os\n",
    "\n",
    "# It's really quite simple - we're comparing PyTorch and OpenVINO YOLOv8n performance\n",
    "# Some easy things to compare would be power, and latency\n",
    "\n",
    "def clean_and_calculate_power(dataframe):\n",
    "    cleaned_df = clean_df(dataframe)\n",
    "    cleaned_df.sort_values(by=\"timestamp\", inplace=True)\n",
    "    # Target word matching and plotting\n",
    "    target_word = 'kepler node joules total dynamic'\n",
    "    closest_matches = difflib.get_close_matches(target_word, cleaned_df.columns, n=6, cutoff=0.05)\n",
    "    print(closest_matches)\n",
    "    cleaned_df['total_joules'] = cleaned_df[closest_matches].sum(axis=1)\n",
    "    ts = cleaned_df[\"timestamp\"]\n",
    "    interval = ts[1] - ts[0]\n",
    "    cleaned_df['power_consumed'] = cleaned_df['total_joules'].diff() / interval\n",
    "    return cleaned_df\n",
    "\n",
    "\n",
    "prom_data_paths = {'ov_cpu_path': \"../../../data/processed/ov_vs_pytorch/prom/ov-cpu_2mbps-rerun/\",\n",
    "                   'pytorch_path': \"../../../data/processed/ov_vs_pytorch/prom/pytorch_2mbps/\"}\n",
    "prom_data_paths = {os.path.basename(x): x for x in subfolders}\n",
    "yolo_data_paths = {key: os.path.join(val, \"yolo_qos.feather\") for key, val in prom_data_paths.items()}\n",
    "\n",
    "total_power = {}\n",
    "response_time = {}\n",
    "for key in prom_data_paths.keys():\n",
    "    paths = []\n",
    "    for work_num in range(1, 6):\n",
    "        temp_path = os.path.join(prom_data_paths[key], f\"worker{work_num}.feather\")\n",
    "        print(temp_path)\n",
    "        paths.append(temp_path)\n",
    "    concatenated_power = pd.concat([df['power_consumed'] for df in [clean_and_calculate_power(read_feather_cached(x)) for x in paths]], axis=1)\n",
    "    total_power[key] = concatenated_power.mean(axis=1)\n",
    "\n",
    "for key in prom_data_paths.keys():\n",
    "    yolo_df = read_feather_cached(yolo_data_paths[key])\n",
    "    yolo_df['total_inference_time'] = yolo_df['inf'] + yolo_df['post'] + yolo_df['pre']\n",
    "    yolo_df['end_to_end_response_time'] = yolo_df['total_inference_time'] + yolo_df['queue']\n",
    "    yolo_df['start'] = pd.to_datetime(yolo_df['start_time'], unit='ms')  # Convert to datetime (optional)\n",
    "    yolo_df.set_index('start', inplace=True)\n",
    "    resampled_df = yolo_df.resample('5S')\n",
    "    response_time[key] = resampled_df.agg({'end_to_end_response_time': 'mean'}).reset_index()['end_to_end_response_time'].rename(key)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#plot the graphs\n",
    "import plotly.express as px\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "power_df = pd.DataFrame.from_dict(total_power)\n",
    "fig = px.line(power_df)\n",
    "fig.update_layout(title='Average Power Over Time', xaxis_title='Time', yaxis_title='Power in Watts',\n",
    "                  yaxis_range=[-20,80])\n",
    "fig.show()\n",
    "\n",
    "queue_df = pd.DataFrame.from_dict(response_time)\n",
    "fig = px.line(queue_df, x=queue_df.index, y=queue_df.columns)\n",
    "fig.update_layout(title='Average Response Time Over Time', xaxis_title='Time', yaxis_title='Reponse Time in MS', yaxis_type='log')\n",
    "fig.show()"
   ],
   "id": "4055423c0479bd54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#plot the graphs\n",
    "import plotly.express as px\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "power_df = pd.DataFrame.from_dict(total_power)\n",
    "fig = px.line(power_df)\n",
    "fig.update_layout(title='Average Power Over Time', xaxis_title='Time', yaxis_title='Power in Watts',\n",
    "                  yaxis_range=[-20,80])\n",
    "fig.show()\n",
    "\n",
    "queue_df = pd.DataFrame.from_dict(response_time)\n",
    "fig = px.line(queue_df, x=queue_df.index, y=queue_df.columns)\n",
    "fig.update_layout(title='Average Response Time Over Time', xaxis_title='Time', yaxis_title='Reponse Time in MS', yaxis_type='log')\n",
    "fig.show()"
   ],
   "id": "7a840fc9dc03317d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import difflib\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from utils.header_cleaner import *\n",
    "\n",
    "def calculate_yolo_input_rate(dataframe):\n",
    "    cleaned_df = dataframe.copy()\n",
    "    cleaned_df.sort_values(by=\"timestamp\", inplace=True)\n",
    "    target_word = 'kafka_server_brokertopicmetrics_bytesin_total yolo_input'\n",
    "    closest_matches = difflib.get_close_matches(target_word, cleaned_df.columns, n=6, cutoff=0.05)\n",
    "    cleaned_df['total_yolo_input'] = cleaned_df[closest_matches].sum(axis=1)\n",
    "    ts = cleaned_df[\"timestamp\"]\n",
    "    interval = ts[1] - ts[0]\n",
    "    cleaned_df['yolo_input_rate'] = cleaned_df['total_yolo_input'].diff() / interval\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df.index = ts\n",
    "    new_df['yolo_input_rate'] = cleaned_df['yolo_input_rate']\n",
    "    return  cleaned_df['yolo_input_rate']\n",
    "\n",
    "download_rate = {}\n",
    "\n",
    "for key in prom_data_paths.keys():\n",
    "    path = prom_data_paths[key] + \"/\" + \"intermediate/full.feather\"\n",
    "    download_rate[key] = calculate_yolo_input_rate(read_feather_cached(path))\n",
    "    # concatenated_df = pd.concat([clean_and_calculate_downloadrate(read_feather_cached(x)) for x in paths], axis=0)\n",
    "\n",
    "yolo_input_df = pd.DataFrame.from_dict(download_rate)\n",
    "# download_rate_df = pd.concat(download_rate.values(), axis=1)\n",
    "\n",
    "fig_download_rate = px.line(yolo_input_df, x=yolo_input_df.index, y=yolo_input_df.columns)\n",
    "fig_download_rate.update_layout(title='Download Rate Over Time', xaxis_title='Time', yaxis_title='Download Rate')\n",
    "fig_download_rate.show()"
   ],
   "id": "3f93d2cb5b3f4c38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "power_df = pd.DataFrame.from_dict(total_power)\n",
    "fig_power = px.line(power_df, title='Average Power Over Time', labels={'value': 'Power in Watts'})\n",
    "fig_power.show()\n",
    "\n",
    "fig_download_rate = px.line(yolo_input_df,\n",
    "                            title='Download Rate Over Time', labels={'yolo_input_rate': 'Download Rate'})\n",
    "fig_download_rate.show()\n",
    "\n",
    "queue_df = pd.DataFrame.from_dict(response_time)\n",
    "fig = px.line(queue_df, x=queue_df.index, y=queue_df.columns)\n",
    "fig.update_layout(title='Average Response Time Over Time', xaxis_title='Time', yaxis_title='Reponse Time in MS', yaxis_type='log')\n",
    "fig.show()"
   ],
   "id": "db52b6f48b0405c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_rate(dataframe, target_word):\n",
    "    cleaned_df = dataframe.copy()\n",
    "    cleaned_df.sort_values(by=\"timestamp\", inplace=True)\n",
    "    closest_matches = difflib.get_close_matches(target_word, cleaned_df.columns, n=6, cutoff=0.05)\n",
    "    match = closest_matches[0]\n",
    "    print(match)\n",
    "    cleaned_df['total_count'] = cleaned_df[match]\n",
    "    ts = cleaned_df[\"timestamp\"]\n",
    "    interval = ts[1] - ts[0]\n",
    "    cleaned_df['rate'] = cleaned_df['total_count'].diff() / interval\n",
    "    return  cleaned_df['rate']"
   ],
   "id": "222913acdb301108",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def plot_rate(keyword, title):\n",
    "    df_dict = {}\n",
    "    \n",
    "    for key in prom_data_paths.keys():\n",
    "        path = prom_data_paths[key] + \"/\" + \"intermediate/full.feather\"\n",
    "        df_dict[key] = calculate_rate(read_feather_cached(path), keyword)\n",
    "        # concatenated_df = pd.concat([clean_and_calculate_downloadrate(read_feather_cached(x)) for x in paths], axis=0)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(df_dict)\n",
    "    # download_rate_df = pd.concat(download_rate.values(), axis=1)\n",
    "    \n",
    "    fig = px.line(df, x=df.index, y=df.columns)\n",
    "    fig.update_layout(title=title, xaxis_title='Time')\n",
    "    fig.show()"
   ],
   "id": "e657c813fef02411",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_rate(\"kafka_server_brokertopicmetrics_bytesin_total yolo_output\", \"yolo output rate\")",
   "id": "e331dc353a8be38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add power data\n",
    "for column in power_df.columns:\n",
    "    fig.add_trace(go.Scatter(x=power_df.index, y=power_df[column], mode='lines', name=f'Power {column}'))\n",
    "\n",
    "# Add response time data\n",
    "for column in queue_df.columns:\n",
    "    fig.add_trace(go.Scatter(x=queue_df.index, y=queue_df[column], mode='lines', name=f'Response Time {column}', yaxis=\"y2\"))\n",
    "\n",
    "# Update layout for dual y-axis\n",
    "fig.update_layout(\n",
    "    title='Power and Response Time Over Time',\n",
    "    xaxis_title='Time',\n",
    "    yaxis=dict(\n",
    "        title='Power in Watts',\n",
    "        range=[-20, 80]\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title='Response Time in MS',\n",
    "        overlaying='y',\n",
    "        side='right',\n",
    "        type='log'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "id": "c7a0055d4a7c442f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "717d91d34e823ef2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b8c214b54b682bfe",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
