{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from pandas.core.interchange.dataframe_protocol import DataFrame\n",
    "\n",
    "\n",
    "# Function to find the subfolders with the file names\n",
    "def find_subfolders_with_file(root_folder, filename):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        if filename in files:\n",
    "            result.append(root)\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "root_folder = '../../../../data/minimized'\n",
    "filename = 'worker1.feather'\n",
    "subfolders = find_subfolders_with_file(root_folder, filename)\n",
    "# subfolders = [x for x in subfolders if \"yolov9\" in x or \"yolov10\" in x]\n",
    "print(subfolders)"
   ],
   "id": "6a5183090ba2659d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from functools import lru_cache\n",
    "from collections import namedtuple\n",
    "\n",
    "def read_feather_cached(file_path):\n",
    "    return read_feather_cached2(file_path).copy()\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def read_feather_cached2(file_path):\n",
    "    return pd.read_feather(file_path)\n",
    "\n",
    "def path_to_name_and_resolution(path):\n",
    "    \"\"\" Run_3 specific naming: '1730280141_yolov9e_1280' -> timestamp_model_resolution \"\"\"\n",
    "    ModelInfo = namedtuple('ModelInfo', ['timestamp', 'model', 'resolution'])\n",
    "    timestamp, model, resolution = path.split(\"_\")\n",
    "    resolution = int(resolution)\n",
    "    return ModelInfo(timestamp, model, resolution)"
   ],
   "id": "ad90a1f2475eed8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "read_feather_cached2.cache_info()",
   "id": "8cb89815be022909",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "from utils.header_cleaner import *\n",
    "import difflib\n",
    "import os\n",
    "\n",
    "# It's really quite simple - we're comparing PyTorch and OpenVINO YOLOv8n performance\n",
    "# Some easy things to compare would be power, and latency\n",
    "\n",
    "def clean_and_calculate_power(dataframe):\n",
    "    cleaned_df = clean_df(dataframe)\n",
    "    cleaned_df.sort_values(by=\"timestamp\", inplace=True)\n",
    "    # Target word matching and plotting\n",
    "    \"\"\"\n",
    "    Compute power as sum of cpu package dynamic and cpu package idle\n",
    "    \n",
    "    - Package should include power from 'CPU cores' and 'CPU uncore'.\n",
    "    - Kepler has separated total power to 'dynamic' and 'idle'\n",
    "    \"\"\"\n",
    "    target_word = 'kepler node package joules total dynamic'\n",
    "    closest_matches = difflib.get_close_matches(target_word, cleaned_df.columns, n=2, cutoff=0.05)\n",
    "    print(closest_matches)\n",
    "    cleaned_df['total_joules'] = cleaned_df[closest_matches].sum(axis=1)\n",
    "    ts = cleaned_df[\"timestamp\"]\n",
    "    # Drop rows where any column from closest_matches is NaN (otherwise power will be close to infinite when data is missing)\n",
    "    cleaned_df.dropna(subset=closest_matches, inplace=True)\n",
    "    time_diff = cleaned_df['timestamp'].diff()\n",
    "    cleaned_df['power_consumed'] = cleaned_df['total_joules'].diff() / time_diff\n",
    "    return cleaned_df\n",
    "\n",
    "\"\"\"\n",
    "Fetch paths to the data\n",
    "\"\"\"\n",
    "prom_data_paths = {os.path.basename(x): x for x in subfolders}\n",
    "yolo_data_paths = {key: os.path.join(val, \"yolo_qos.feather\") for key, val in prom_data_paths.items()}\n",
    "\n",
    "\"\"\"\n",
    "Compute avg powers from prom data\n",
    "\"\"\"\n",
    "total_power = {}\n",
    "for key in prom_data_paths.keys():\n",
    "    paths = []\n",
    "    for work_num in range(1, 6):\n",
    "        temp_path = os.path.join(prom_data_paths[key], f\"worker{work_num}.feather\")\n",
    "        print(temp_path)\n",
    "        paths.append(temp_path)\n",
    "    concatenated_power = pd.concat([df['power_consumed'] for df in [clean_and_calculate_power(read_feather_cached(x)) for x in paths]], axis=1)\n",
    "    model_info = path_to_name_and_resolution(key)\n",
    "    if model_info.resolution not in total_power:\n",
    "        total_power[model_info.resolution] = {}\n",
    "    total_power[model_info.resolution][model_info.model] = concatenated_power.sum(axis=1)\n",
    "\n",
    "\"\"\"\n",
    "Get corresponding yolo stats for each model \n",
    "\"\"\"\n",
    "response_time = {}\n",
    "for key in prom_data_paths.keys():\n",
    "    yolo_df = read_feather_cached(yolo_data_paths[key])\n",
    "    yolo_df['total_inference_time'] = yolo_df['inf'] + yolo_df['post'] + yolo_df['pre']\n",
    "    yolo_df['end_to_end_response_time'] = yolo_df['total_inference_time'] + yolo_df['queue']\n",
    "    yolo_df['start'] = pd.to_datetime(yolo_df['start_time'], unit='ms')  # Convert to datetime (optional)\n",
    "    yolo_df.set_index('start', inplace=True)\n",
    "    resampled_df = yolo_df.resample('5S')\n",
    "    model_info = path_to_name_and_resolution(key)\n",
    "    if model_info.resolution not in response_time:\n",
    "        response_time[model_info.resolution] = {}\n",
    "    response_time[model_info.resolution][model_info.model] = resampled_df.agg({'end_to_end_response_time': 'mean'}).reset_index()['end_to_end_response_time'].rename(key)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Function to compute simple moving average\n",
    "def moving_average(data, window_size):\n",
    "    return data.rolling(window=window_size).mean()\n",
    "\n",
    "# You can adjust the window size for different levels of smoothing\n",
    "window_size = 3\n",
    "\n",
    "for resolution in sorted(response_time.keys()):\n",
    "    queue_df = pd.DataFrame.from_dict(response_time[resolution])\n",
    "    fig = px.line(queue_df, x=queue_df.index, y=queue_df.columns)\n",
    "    fig.update_layout(title=f'End-to-end latency (Resolution: {resolution})', xaxis_title='Time', yaxis_title='Reponse Time in MS', yaxis_type='log')\n",
    "    fig.show()"
   ],
   "id": "319cd60cc5b7fd60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "power_response_ratio = {}\n",
    "for resolution, models in total_power.items():\n",
    "    power_response_ratio[resolution] = {}\n",
    "    for model in models.keys():\n",
    "        power_df = pd.DataFrame(total_power[resolution][model])\n",
    "        response_df = pd.DataFrame(response_time[resolution][model])\n",
    "        if not power_df.empty and not response_df.empty:\n",
    "            response_df_aligned, power_df_aligned = response_df.align(power_df, join='inner', axis=0)\n",
    "            if not response_df_aligned.empty and not power_df_aligned.empty:\n",
    "                power_response_ratio[resolution][model] = response_df_aligned.div(power_df_aligned.values, axis=0, level=0)\n",
    "\n",
    "for resolution, models in sorted(power_response_ratio.items()):\n",
    "    ratio_df = pd.concat(models, axis=1)\n",
    "    ratio_df.columns = [f\"{model}_ratio\" for model in models.keys()]\n",
    "    fig = px.line(ratio_df, title=f'Latency per Watt (Resolution: {resolution})')\n",
    "    fig.update_layout(xaxis_title='Time', yaxis_title='Response Time per Watt')\n",
    "    fig.show()"
   ],
   "id": "8a989dcac37d74df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "power_response_ratio = {}\n",
    "for resolution, models in total_power.items():\n",
    "    power_response_ratio[resolution] = {}\n",
    "    for model in models.keys():\n",
    "        power_df = pd.DataFrame(total_power[resolution][model])\n",
    "        response_df = pd.DataFrame(response_time[resolution][model])\n",
    "        if not power_df.empty and not response_df.empty:\n",
    "            response_df_aligned, power_df_aligned = response_df.align(power_df, join='inner', axis=0)\n",
    "            if not response_df_aligned.empty and not power_df_aligned.empty:\n",
    "                power_response_ratio[resolution][model] = power_df_aligned.div(response_df_aligned.values, axis=0, level=0)\n",
    "\n",
    "for resolution, models in sorted(power_response_ratio.items()):\n",
    "    ratio_df = pd.concat(models, axis=1)\n",
    "    ratio_df.columns = [f\"{model}_ratio\" for model in models.keys()]\n",
    "    fig = px.line(ratio_df, title=f'Watt per latency (Resolution: {resolution})')\n",
    "    fig.update_layout(xaxis_title='Time', yaxis_title='Watt per latency')\n",
    "    fig.show()"
   ],
   "id": "18200cb78599ba9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "80cf6d9d3afee29b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
