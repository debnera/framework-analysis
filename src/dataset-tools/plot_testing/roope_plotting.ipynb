{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T12:30:05.163091Z",
     "start_time": "2024-08-21T12:30:05.160519Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def clean_df(dataframe):\n",
    "    df = dataframe\n",
    "    #Count number of rows and cols in the original df\n",
    "    print(f\"Loaded {len(df)} rows and {len(df.columns)} columns\")\n",
    "    # Count the number of unique values in each column\n",
    "    unique_counts = df.nunique()\n",
    "    # Find all static columns (columns with only one or two unique values)\n",
    "    static_columns = unique_counts[unique_counts <= 2].index\n",
    "    # Remove the static columns from the dataframe\n",
    "    df = df.drop(static_columns, axis=1)\n",
    "    print(f\"Removing {len(static_columns)} static columns ({len(df.columns)} remaining)\")\n",
    "    if len(df.columns) < 100:\n",
    "        # Only display if the df is small enough to not stall the IDE (thousands of columns really slows things down)\n",
    "        df.head()\n",
    "\n",
    "    # changing the dataframe headers to a more human-readable format\n",
    "    return clean_up_headers(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80394548ddfeedac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T12:30:07.098706Z",
     "start_time": "2024-08-21T12:30:07.086097Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Next we will create plots of power consumption vs quality of service for 1 (low), 2 (stable), and 4 (high) mbps input of data\n",
    "from utils.header_cleaner import clean_up_headers\n",
    "import difflib\n",
    "\n",
    "\n",
    "def clean_and_calculate_power(dataframe):\n",
    "    cleaned_df = clean_df(dataframe)\n",
    "    #target word matching and plotting\n",
    "    target_word = 'kepler node joules total'\n",
    "    closest_matches = difflib.get_close_matches(target_word, cleaned_df.columns, n=6, cutoff=0.05)\n",
    "    cleaned_df['total_joules'] = cleaned_df[closest_matches].sum(axis=1)\n",
    "    cleaned_df['power_consumed'] = cleaned_df['total_joules'].diff()\n",
    "    return cleaned_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa70cdbaf5bc3112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T12:33:25.945541Z",
     "start_time": "2024-08-21T12:31:47.885762Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "average_power = {}\n",
    "\n",
    "input_speeds = [9, 1, 2, 4]\n",
    "for mbps in input_speeds:\n",
    "    if mbps == 9:\n",
    "        prom_path = \"../../../data/processed/19.8_ajo/prom/linear_9/\"    \n",
    "    else:\n",
    "        path = \"../../../data/processed/8.8_ajo/\"\n",
    "        prom_path = path + f\"prom/{mbps} mbps/\"\n",
    "    for work_num in range(1, 6):\n",
    "        temp_path = prom_path + f\"worker{work_num}.feather\"\n",
    "        print(temp_path)\n",
    "        concatenated_power = pd.concat([df['power_consumed'] for df in [clean_and_calculate_power(pd.read_feather(temp_path))]], axis=1)\n",
    "        average_power[f'{mbps}'] = concatenated_power.mean(axis=1)\n",
    "# 1. yolo total time vs average power consumption per worker\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e63af8592eeffe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T12:33:54.407136Z",
     "start_time": "2024-08-21T12:33:51.747594Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "def min_max_norm(dataframe, col_name):\n",
    "    return (dataframe[col_name] - dataframe[col_name].min()) / (dataframe[col_name].max() - dataframe[col_name].min())\n",
    "\n",
    "power_consumption_df = pd.DataFrame()\n",
    "for mbps in input_speeds:\n",
    "    if mbps == 9:\n",
    "        yolo_df = pd.read_feather(\"../../../data/processed/19.8_ajo/yolo/yolo_qos.feather\")\n",
    "        yolo_df = yolo_df.loc[yolo_df['start_time'] > 1724070345000]\n",
    "\n",
    "    else:\n",
    "        yolo_df = pd.read_feather(f\"../../../data/processed/8.8_ajo/yolo/{mbps}_mbps/yolo_qos.feather\")\n",
    "\n",
    "\n",
    "    result_df = pd.DataFrame({f'average_power_consumed_{mbps}': average_power[f'{mbps}']})\n",
    "    result_df[f'queue_{mbps}'] = yolo_df['queue']\n",
    "    power_consumption_df = pd.concat([power_consumption_df, result_df], axis=1)\n",
    "    # Assuming result_df is your DataFrame\n",
    "    # 2. queue time, total power consumption, and images processed per second over time all into one graph\n",
    "    yolo_df['start'] = pd.to_datetime(yolo_df['start_time'], unit='ms')  # Convert to datetime (optional)\n",
    "    # Group by 10-second intervals and count the number of rows in each interval\n",
    "    intervals = yolo_df.resample('5S', on='start')\n",
    "    \n",
    "    \n",
    "    interval_counts_df = intervals.size().reset_index(name='yolo_instances_processed')\n",
    "    yolo_df.set_index('start', inplace=True)\n",
    "    average_queue_df = yolo_df.resample('5S').agg({'queue': 'mean'})\n",
    "    average_queue_df.reset_index(inplace=True)\n",
    "    average_queue_df = average_queue_df.rename(columns={'queue': 'queue_time'})\n",
    "    \n",
    "    col1 = min_max_norm(average_queue_df, 'queue_time')\n",
    "    \n",
    "    col2 = min_max_norm(result_df, f'average_power_consumed_{mbps}')\n",
    "    #col2 = result_df[f'average_power_consumed_{mbps}']\n",
    "\n",
    "    col3 = min_max_norm(interval_counts_df, 'yolo_instances_processed')\n",
    "    queue_power_images_df = pd.concat([col1, col2, col3], axis=1)\n",
    "    fig = px.line(queue_power_images_df, x=queue_power_images_df.index, y=queue_power_images_df.columns)\n",
    "    fig.update_layout(title='Queue Time, Average Power, and Instances Processed Over Time', xaxis_title='Time', yaxis_title='Normalized')\n",
    "    fig.show()\n",
    "    #queue_power_images_df.plot()\n",
    "# \n",
    "traces = []\n",
    "pcd = power_consumption_df\n",
    "for mbps in reversed(input_speeds):\n",
    "    traces.append(go.Scatter(x=pcd[f'average_power_consumed_{mbps}'], y=pcd[f'queue_{mbps}'], mode='markers', name=f'{mbps}_mbps'))\n",
    "# Combine traces into a figure\n",
    "fig = go.Figure(data=traces)\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    title='Power Consumption vs Queue Time for 1, 2, 4, 9 mbps input speed',\n",
    "    xaxis_title='Power Consumption',\n",
    "    yaxis_title='Queue Time'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "#jupyter nbconvert --clear-output --inplace src/dataset-tools/plot_testing/roope_plotting.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c63efd3e9b83dd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T12:34:04.638928Z",
     "start_time": "2024-08-21T12:34:04.465898Z"
    }
   },
   "outputs": [],
   "source": [
    "#here are scripts for looking at multiple measure of QoS\n",
    "# - inf + pre + post (Total Inference Time)\n",
    "# - inf + pre + post + queue (end-to-end response Time)\n",
    "# - images per second processed vs energy expenditure (system throughput wrt to energy usage)\n",
    "# The idea is to compare the different QOS metrics under different severities of load\n",
    "\n",
    "qos_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for mbps in input_speeds:\n",
    "\n",
    "    if mbps == 9:\n",
    "        yolo_df = pd.read_feather(\"../../../data/processed/19.8_ajo/yolo/yolo_qos.feather\")\n",
    "        yolo_df = yolo_df.loc[yolo_df['start_time'] > 1724070345000]\n",
    "    else:\n",
    "        yolo_df = pd.read_feather(f\"../../../data/processed/8.8_ajo/yolo/{mbps}_mbps/yolo_qos.feather\")\n",
    "\n",
    "\n",
    "\n",
    "    yolo_df['total_inference_time'] = yolo_df['inf'] + yolo_df['post'] + yolo_df['pre']\n",
    "    yolo_df['end_to_end_response_time'] = yolo_df['total_inference_time'] + yolo_df['queue']\n",
    "    yolo_df['start'] = pd.to_datetime(yolo_df['start_time'], unit='ms')  # Convert to datetime (optional)\n",
    "        \n",
    "    yolo_df.set_index('start', inplace=True)\n",
    "    resampled_df = yolo_df.resample('5S')\n",
    "    qos_df[f'end_to_end_{mbps}'] = resampled_df.agg({'end_to_end_response_time': 'mean'}).reset_index()['end_to_end_response_time'] / 1000\n",
    "    qos_df[f'throughput_{mbps}'] = qos_df[f'end_to_end_{mbps}'] / pcd[f'average_power_consumed_{mbps}']\n",
    "\n",
    "\n",
    "#qos_df[f'total_inf_{mbps}'] = resampled_df.agg({'total_inference_time': 'mean'}).reset_index()['total_inference_time']\n",
    "    \n",
    "# bar chart:\n",
    "# x: eri runit (esim ne mbps)\n",
    "# y: avg_latency, avg_power, avg_latency_per_avg_power  (nää voi plotata jollain error-barilla et se näyttää samassa palkissa min,max,avg tai sit 95-confidence intervallin ja averagen)\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "qos_map = {}\n",
    "errors = {}\n",
    "for mbps in input_speeds:\n",
    "    errors[f'{mbps}'] = []\n",
    "    qos_map[f'{mbps}'] = []\n",
    "    qos_map[f'{mbps}'].append(qos_df[f'end_to_end_{mbps}'].mean())\n",
    "    qos_map[f'{mbps}'].append(pcd[f'average_power_consumed_{mbps}'].mean())\n",
    "    qos_map[f'{mbps}'].append(qos_df[f'throughput_{mbps}'].mean())\n",
    "    for data in [qos_df[f'end_to_end_{mbps}'], pcd[f'average_power_consumed_{mbps}'], qos_df[f'throughput_{mbps}']]:\n",
    "        sem = stats.sem(data)  # Standard error of the mean\n",
    "        conf_interval = sem * stats.t.ppf((1 + 0.95) / 2., len(data) - 1)  # 95% confidence interval\n",
    "        errors[f'{mbps}'].append(conf_interval)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Assuming each list in the dictionary represents a different category (e.g., A, B, C)\n",
    "categories = ['latency', 'power', 'latency per power']\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    y_means = []\n",
    "    y_errors = []\n",
    "    for key in qos_map.keys():\n",
    "        y_means.append(qos_map[key][i])\n",
    "        y_errors.append(errors[key][i])\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=list(qos_map.keys()),\n",
    "        y=y_means,\n",
    "        name=category,\n",
    "        error_y=dict(\n",
    "            type='data',\n",
    "            array=y_errors,\n",
    "            visible=True\n",
    "        )\n",
    "    ))\n",
    "\n",
    "# Update layout for better readability\n",
    "fig.update_layout(\n",
    "    barmode='group',  # Group bars for each x value\n",
    "    title='Grouped Bar Graph with 95% Confidence Intervals',\n",
    "    xaxis_title='Keys',\n",
    "    yaxis_title='Queue Time (s) / Power (W) / latency per watt',\n",
    "    legend_title='Categories'\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4336d66881bc4b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
