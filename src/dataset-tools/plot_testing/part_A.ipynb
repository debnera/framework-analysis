{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T09:13:29.883625Z",
     "start_time": "2024-08-27T09:12:39.302900Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.header_cleaner import *\n",
    "import difflib\n",
    "\n",
    "#its really quite sinple - we're comparing pytorch and openvino yolov8n performance\n",
    "# some easy things to compare would be power, and latency\n",
    "\n",
    "def clean_and_calculate_power(dataframe):\n",
    "    cleaned_df = clean_df(dataframe)\n",
    "    #target word matching and plotting\n",
    "    target_word = 'kepler node joules total'\n",
    "    closest_matches = difflib.get_close_matches(target_word, cleaned_df.columns, n=6, cutoff=0.05)\n",
    "    cleaned_df['total_joules'] = cleaned_df[closest_matches].sum(axis=1)\n",
    "    cleaned_df['power_consumed'] = cleaned_df['total_joules'].diff()\n",
    "    return cleaned_df\n",
    "\n",
    "\n",
    "prom_data_paths = {'ov_cpu_path': \"../../../data/processed/partA/prom/prom_ov/\",\n",
    "              'pytorch_path': \"../../../data/processed/partA/prom/prom_pytorch/\"}\n",
    "yolo_data_paths = {'ov_cpu_path': \"../../../data/processed/partA/yolo/ov/yolo_qos.feather\",\n",
    "                   'pytorch_path': \"../../../data/processed/partA/yolo/pytorch/yolo_qos.feather\"}\n",
    "total_power = {}\n",
    "response_time = {}\n",
    "for key in prom_data_paths.keys():\n",
    "    for work_num in range(1, 6):\n",
    "        temp_path = prom_data_paths[key] + f\"worker{work_num}.feather\"\n",
    "        print(temp_path)\n",
    "        concatenated_power = pd.concat([df['power_consumed'] for df in [clean_and_calculate_power(pd.read_feather(temp_path))]], axis=1)\n",
    "        total_power[key] = concatenated_power.mean(axis=1)\n",
    "\n",
    "for key in prom_data_paths.keys():\n",
    "    yolo_df = pd.read_feather(yolo_data_paths[key])\n",
    "    yolo_df['total_inference_time'] = yolo_df['inf'] + yolo_df['post'] + yolo_df['pre']\n",
    "    yolo_df['end_to_end_response_time'] = yolo_df['total_inference_time'] + yolo_df['queue']\n",
    "    yolo_df['start'] = pd.to_datetime(yolo_df['start_time'], unit='ms')  # Convert to datetime (optional)\n",
    "    yolo_df.set_index('start', inplace=True)\n",
    "    resampled_df = yolo_df.resample('5S')\n",
    "    response_time[key] = resampled_df.agg({'end_to_end_response_time': 'mean'}).reset_index()['end_to_end_response_time']\n",
    "   \n",
    "#data has now been loaded, time to graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c52f698a2a2268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T09:14:25.001511Z",
     "start_time": "2024-08-27T09:14:24.937336Z"
    }
   },
   "outputs": [],
   "source": [
    "for key in prom_data_paths.keys():\n",
    "    yolo_df = pd.read_feather(yolo_data_paths[key])\n",
    "    yolo_df['total_inference_time'] = yolo_df['inf'] + yolo_df['post'] + yolo_df['pre']\n",
    "    yolo_df['end_to_end_response_time'] = yolo_df['total_inference_time'] + yolo_df['queue']\n",
    "    yolo_df['start'] = pd.to_datetime(yolo_df['start_time'], unit='ms')  # Convert to datetime (optional)\n",
    "    yolo_df.set_index('start', inplace=True)\n",
    "    resampled_df = yolo_df.resample('5S')\n",
    "    response_time[key] = resampled_df.agg({'end_to_end_response_time': 'mean'}).reset_index()['end_to_end_response_time'].rename(key)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0a15c1f043610b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T09:14:29.732747Z",
     "start_time": "2024-08-27T09:14:27.363966Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot the graphs\n",
    "import plotly.express as px\n",
    "\n",
    "power_df = pd.concat([total_power['ov_cpu_path'], total_power['pytorch_path']], axis=1).rename(columns={0: 'ov_cpu', 1: 'pytorch'})\n",
    "fig = px.line(power_df, x=power_df.index, y=power_df.columns)\n",
    "fig.update_layout(title='Average Power Over Time', xaxis_title='Time', yaxis_title='Power in Watts')\n",
    "fig.show()\n",
    "\n",
    "queue_df = pd.concat([response_time['ov_cpu_path'], response_time['pytorch_path']], axis=1)\n",
    "fig = px.line(queue_df, x=queue_df.index, y=queue_df.columns)\n",
    "fig.update_layout(title='Average Response Time Over Time', xaxis_title='Time', yaxis_title='Reponse Time in MS')\n",
    "fig.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
