{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5183090ba2659d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T10:47:47.516597Z",
     "start_time": "2025-01-03T10:47:47.500398Z"
    }
   },
   "outputs": [],
   "source": [
    "import common_utils\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Example usage\n",
    "root_folder = '../../../data_warehouse/minimized_warehouse_4'\n",
    "filename = 'worker1.feather'\n",
    "subfolders = common_utils.find_subfolders_with_file(root_folder, filename)\n",
    "print(subfolders)\n",
    "prom_data_paths = {os.path.basename(x): x for x in subfolders}\n",
    "yolo_data_paths = {key: os.path.join(val, \"worker_qos.feather\") for key, val in prom_data_paths.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd965984ae3c32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T10:47:47.889956Z",
     "start_time": "2025-01-03T10:47:47.593192Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get corresponding yolo stats for each model \n",
    "\"\"\"\n",
    "response_time = {}\n",
    "for key in prom_data_paths.keys():\n",
    "    try:\n",
    "        yolo_df = common_utils.read_feather_cached(yolo_data_paths[key])\n",
    "    except:\n",
    "        print(f\"Failed to read {key}\")\n",
    "        continue\n",
    "    yolo_df['total_inference_time'] = yolo_df['inf'] + yolo_df['post'] + yolo_df['pre']\n",
    "    yolo_df['end_to_end_response_time'] = yolo_df['total_inference_time'] + yolo_df['queue']\n",
    "    yolo_df['end'] = pd.to_datetime(yolo_df['end_time'], unit='ms')  # Convert to datetime (optional)\n",
    "    yolo_df.set_index('end', inplace=True)\n",
    "    resampled_df = yolo_df.resample('5s')\n",
    "    model_info = common_utils.path_to_workers_and_pcl_size(key)\n",
    "    if model_info.resolution not in response_time:\n",
    "        response_time[model_info.resolution] = {}\n",
    "    response_time[model_info.resolution][model_info.num_vehicles] = resampled_df.agg({'end_to_end_response_time': 'count'}).reset_index()['end_to_end_response_time'].rename(key) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecea8b0fdf4dbbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T10:47:48.137186Z",
     "start_time": "2025-01-03T10:47:47.967320Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "for resolution in sorted(response_time.keys()):\n",
    "    queue_df = pd.DataFrame.from_dict(response_time[resolution])\n",
    "    fig = px.line(queue_df, x=queue_df.index, y=queue_df.columns)\n",
    "    fig.update_layout(title=f'PCL throughput (Resolution: {resolution})', xaxis_title='Time', yaxis_title='PCL per second', yaxis_type='linear')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb789c0d428be639",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T10:47:48.291081Z",
     "start_time": "2025-01-03T10:47:48.216207Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Dictionary to store max throughput for each model\n",
    "max_throughput = {}\n",
    "\n",
    "for resolution in sorted(response_time.keys()):\n",
    "    queue_df = pd.DataFrame.from_dict(response_time[resolution])\n",
    "    \n",
    "    # Calculate the maximum throughput for each model\n",
    "    max_throughput[resolution] = queue_df.max()\n",
    "\n",
    "# Create a DataFrame from the max throughput dictionary\n",
    "max_throughput_df = pd.DataFrame(max_throughput)\n",
    "\n",
    "# Sort \n",
    "max_throughput_df_sorted = common_utils.sort_by_model_size_then_version(max_throughput_df)\n",
    "\n",
    "# Plot the maximum throughput for each model\n",
    "fig = px.bar(max_throughput_df_sorted, barmode='group')\n",
    "fig.update_layout(title='Maximum Throughput per Model', xaxis_title='Model', yaxis_title='Max Images per Second', yaxis_type='linear')\n",
    "fig.show()\n",
    "\n",
    "fig = px.bar(max_throughput_df_sorted, barmode='group')\n",
    "fig.update_layout(title='Maximum Throughput per Model', xaxis_title='Model', yaxis_title='Max Images per Second', yaxis_type='log')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629adbdbbfa9c0f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T10:47:48.295764800Z",
     "start_time": "2024-11-28T11:50:43.822943Z"
    }
   },
   "outputs": [],
   "source": [
    "max_throughput_df_sorted.to_csv(\"table_plots/data_throughput.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8992b4ecc1015cbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T10:47:48.298311400Z",
     "start_time": "2024-11-28T11:50:55.739173Z"
    }
   },
   "outputs": [],
   "source": [
    "max_throughput_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431c77a89dc94031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
