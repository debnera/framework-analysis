{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "\n",
    "data_path = \"../data/minimized_run_5/1732116960_yolo11n_160/\"\n",
    "\n",
    "folder_path = data_path\n",
    "file_sizes = {file: os.path.getsize(os.path.join(folder_path, file)) / (1024 * 1024) for file in os.listdir(folder_path)}\n",
    "\n",
    "sorted_files_by_size = dict(sorted(file_sizes.items(), key=lambda item: item[1]))\n",
    "\n",
    "sorted_files_by_size"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "folder_path = data_path\n",
    "worker_dataframes = [pd.read_feather(os.path.join(folder_path, file)) for file in os.listdir(folder_path) if file.startswith('worker') and file.endswith('.feather')]\n",
    "for col in worker_dataframes[0].columns:\n",
    "    print(col)\n",
    "# worker_dataframes[0].columns\n",
    "\n",
    "# kepler_process_package_joules_total -> Idle + dynamic + pid (int) + container_id (text or hex) + command (text)\n",
    "# --> command: python3.8\n",
    "# --> command: runc:[1:CHILD]\n",
    "# kepler_process_cpu_instructions_total -> command, container_id, instance, pid\n",
    "# kepler_container_package_joules_total -> container_id, container_name, container_namespace, instance, dynamic/idle, pod_name\n",
    "\n",
    "# node_network_transmit_* -> device: lo/tunl0 or cali{hex} or enp88s0\n",
    "# node_network_send_* -> device: lo/tunl0 or cali{hex} or enp88s0\n",
    "# node_network_receive_* -> device: lo/tunl0 or cali{hex} or enp88s0\n",
    "\n",
    "# instance:node_cpu_* -> instance\n",
    "# instance:node_memory_* -> instance\n",
    "# instance:node_network_* -> instance\n",
    "# instance:* -> instance\n",
    "# node_* -> instance\n",
    "# node_cpu_seconds_total -> cpu, instance, mode\n",
    "\n",
    "# Summary:\n",
    "# Can use: kepler_container_* > container_namespace: workloadb\n",
    "# Cannot use: kepler_process_* -> too many IDs and must guess the workload process (python3.8 is the best guess + subprocesses?)\n",
    "\n",
    "# Idea: Compare global worker stats to container stats for predicting the application (or: worker stats vs container stats)"
   ],
   "id": "20fdb496af64598b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "def try_load_json(column_json: str):\n",
    "    try:\n",
    "        return json.loads(column_json)\n",
    "    except json.JSONDecodeError:\n",
    "        return None\n",
    "\n",
    "def rename_workers(column_json: str):\n",
    "    # Affects key-pairs: \"instance\":\"worker1\"\n",
    "    #\n",
    "    # Rename instances (worker1,worker2,worker3,worker4,worker5) -> \"worker\"\n",
    "    for i in range(1,6):\n",
    "        column_json = column_json.replace(\"worker\" + str(i), \"worker\")\n",
    "    return column_json\n",
    "\n",
    "def filter_namespaces(column_json: str):\n",
    "    # Filter out key-pairs such as: \"container_namespace\":\"kube-system\"\n",
    "    json_obj = try_load_json(column_json)\n",
    "    # Accept all columns that cannot be parsed as json\n",
    "    if json_obj is None:\n",
    "        return True\n",
    "    # Accept all columns that do not have a namespace\n",
    "    if \"container_namespace\" not in json_obj:\n",
    "        return True\n",
    "    # If the column has namespace, accept only the \"workloadb\" namespace\n",
    "    container_namespace: str = json_obj[\"container_namespace\"]\n",
    "    if container_namespace == \"workloadb\":  # All YOLO workload applications run under the \"workloadb\" namespace\n",
    "        return True\n",
    "    # Filter out all other namespaces\n",
    "    return False\n",
    "\n",
    "def filter_go_specific(column_json: str):\n",
    "    # Filter out columns related to go-language garbage collection (e.g., go_memstats_last_gc_time_seconds)\n",
    "    json_obj = try_load_json(column_json)\n",
    "    # Accept all columns that cannot be parsed as json\n",
    "    if json_obj is None:\n",
    "        return True\n",
    "    # Accept all columns, except go specific columns\n",
    "    column_name: str = json_obj[\"__name__\"]\n",
    "    if not column_name.startswith(\"go_\"):\n",
    "        return True\n",
    "    # Filter out all other namespaces\n",
    "    return False\n",
    "\n",
    "def filter_process_specific(column_json: str):\n",
    "    # Filter out columns about kepler_process_*, since they have very specific process ids and container ids.\n",
    "    # These processes are also included in the kepler_container.\n",
    "    json_obj = try_load_json(column_json)\n",
    "    # Accept all columns that cannot be parsed as json\n",
    "    if json_obj is None:\n",
    "        return True\n",
    "    # Accept all columns, except process specific columns\n",
    "    column_name: str = json_obj[\"__name__\"]\n",
    "    if not column_name.startswith(\"kepler_process_\"):\n",
    "        return True\n",
    "    # Filter out all other namespaces\n",
    "    return False\n",
    "\n",
    "def filter_durations(column_json: str):\n",
    "    # Filter out columns like:\n",
    "    # - go_gc_duration_seconds_count\n",
    "    # - go_gc_duration_seconds_sum\n",
    "    # - node_scrape_collector_duration_seconds\n",
    "    # - scrape_duration_seconds\n",
    "    # - go_gc_duration_seconds\n",
    "\n",
    "    json_obj = try_load_json(column_json)\n",
    "    # Accept all columns that cannot be parsed as json\n",
    "    if json_obj is None:\n",
    "        return True\n",
    "    # Accept all columns, columns with \"duration\"\n",
    "    column_name: str = json_obj[\"__name__\"]\n",
    "    if \"_duration_\" not in column_name:\n",
    "        return True\n",
    "    # Filter out all other namespaces\n",
    "    return False\n",
    "\n",
    "def rename_container_columns(column_json: str):\n",
    "    \"\"\"\n",
    "    Removes \"container_id\" and \"pod_name\" from the column JSON string.\n",
    "\n",
    "    Example: {\"__name__\":\"kepler_container_cpu_instructions_total\",\"container_id\":\"e4f3637bcbcb4fa1db77b269c7a1eec025fce7bb982e38b4ba668804f371b90f\",\"container_name\":\"yolo-consumer\",\"container_namespace\":\"workloadb\",\"instance\":\"worker\",\"pod_name\":\"yolo-consumer-64478765c9-k5bvh\"}\n",
    "    \"\"\"\n",
    "    json_obj = try_load_json(column_json)\n",
    "    # Do nothing if the column cannot be parsed as json\n",
    "    if json_obj is None:\n",
    "        return column_json\n",
    "\n",
    "    # Remove \"container_id\" and \"pod_name\" key-value pairs\n",
    "    json_obj.pop(\"container_id\", None)\n",
    "    json_obj.pop(\"pod_name\", None)\n",
    "\n",
    "    # Return the JSON object as a string\n",
    "    return json.dumps(json_obj)\n",
    "\n",
    "\"\"\"\n",
    "Convert monontonically increasing cols to rates (e.g., total joules to joules per unit of time)\n",
    "\"\"\"\n",
    "def get_counters(df):\n",
    "    return [col for col in df.columns if df[col].is_monotonic_increasing]\n",
    "\n",
    "def convert_to_rates(df, counters):\n",
    "    rate_dataframes = []\n",
    "    for counter in counters:\n",
    "        json_obj = try_load_json(counter)\n",
    "        if json_obj is None:\n",
    "            continue\n",
    "        name = json_obj[\"__name__\"]\n",
    "        new_name = name + \"_rate\"\n",
    "        new_name = new_name.replace(\"_total_\", \"_\")  # Some counters have \"total\" in their name\n",
    "        json_obj[\"__name__\"] = new_name\n",
    "        new_column = json.dumps(json_obj)\n",
    "        rate_dataframes.append(df[counter].diff().rename(new_column))\n",
    "\n",
    "    # Combine the existing dataframe with the new rate dataframes\n",
    "    df = pd.concat([df] + rate_dataframes, axis=1)\n",
    "    return df\n"
   ],
   "id": "e37355519c2ee928",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = worker_dataframes[0]\n",
    "\n",
    "\"\"\" Renaming columns to more generalized format (e.g., \"worker\" instead of \"worker1\") \"\"\"\n",
    "df.columns = [rename_workers(col) for col in df.columns]\n",
    "df.columns = [rename_container_columns(col) for col in df.columns]\n",
    "\n",
    "\"\"\" Filtering out columns that are useless or difficult to use (e.g., process specific metrics) \"\"\"\n",
    "filtered_columns = [col for col in df.columns if filter_namespaces(col)]\n",
    "df = df[filtered_columns]\n",
    "\n",
    "filtered_columns = [col for col in df.columns if filter_go_specific(col)]\n",
    "df = df[filtered_columns]\n",
    "\n",
    "filtered_columns = [col for col in df.columns if filter_process_specific(col)]\n",
    "df = df[filtered_columns]\n",
    "\n",
    "filtered_columns = [col for col in df.columns if filter_durations(col)]\n",
    "df = df[filtered_columns]\n",
    "\n",
    "\"\"\" Convert monontonically increasing cols to rates (counters to gauges) (e.g., total joules to joules per unit of time) \"\"\"\n",
    "counters = get_counters(df)\n",
    "df = convert_to_rates(df, counters)\n",
    "filtered_columns = [col for col in df.columns if col not in counters]\n",
    "df = df[filtered_columns]\n",
    "df = df.copy()  # Get defragmented copy of the df after all the edits\n",
    "\n",
    "\n",
    "\"\"\" Print remaining cols \"\"\"\n",
    "for col in df.columns:\n",
    "    print(col)"
   ],
   "id": "762f27977b93136b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Get and print all monotonic columns (e.g., counters)\n",
    "\n",
    "These cannot be used directly for machine learning, since they are specific to how long the cluster/experiment has been running.\n",
    "\"\"\"\n",
    "counters = []\n",
    "for col in df.columns:\n",
    "    if df[col].is_monotonic_increasing:\n",
    "        counters.append(col)\n",
    "        print(col)"
   ],
   "id": "f3785e4724fb24bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4376855860a54e46",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
