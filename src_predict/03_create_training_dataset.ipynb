{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# Path to the directory containing feather files\n",
    "feather_directory = \"combined_data\"\n",
    "\n",
    "# Initialize an empty list to store individual DataFrames with yolomodel\n",
    "dataframes = []\n",
    "\n",
    "# Read each feather file\n",
    "for file in glob.glob(f\"{feather_directory}/*.feather\"):\n",
    "    # Extract the base filename\n",
    "    filename = os.path.basename(file)\n",
    "\n",
    "    # Extract yolomodel from the filename\n",
    "    yolomodel = filename.split('_')[1]\n",
    "\n",
    "    # Read the dataframe\n",
    "    df = pd.read_feather(file)\n",
    "\n",
    "    # Remove timestamp column, assuming it's named 'timestamp' as a placeholder\n",
    "    df = df.drop(columns=['timestamp']) if 'timestamp' in df.columns else df\n",
    "\n",
    "    # Add the extracted yolomodel as a new column\n",
    "    df['yolomodel'] = yolomodel\n",
    "\n",
    "    # Append to the list of DataFrames\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Determine common columns across all DataFrames\n",
    "common_columns = list(set.intersection(*(set(df.columns) for df in dataframes)))\n",
    "\n",
    "# Standardize each DataFrame to have only columns that are common across all DataFrames\n",
    "dataframes = [df[common_columns] for df in dataframes]\n",
    "\n",
    "# Combine all DataFrames into a single DataFrame\n",
    "os.makedirs(\"datasets\", exist_ok=True)\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "combined_df.to_feather(\"datasets/predict_yolomodel.feather\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# Path to the directory containing feather files\n",
    "feather_directory = \"combined_data\"\n",
    "\n",
    "# Initialize an empty list to store individual DataFrames with yolomodel\n",
    "dataframes = []\n",
    "\n",
    "remaining = 2000\n",
    "\n",
    "# Read each feather file\n",
    "for file in glob.glob(f\"{feather_directory}/*.feather\"):\n",
    "    # Extract the base filename\n",
    "    filename = os.path.basename(file)\n",
    "\n",
    "    # Extract yolomodel from the filename\n",
    "    yolomodel = filename.split('_')[1]\n",
    "\n",
    "    # Read the dataframe\n",
    "    df = pd.read_feather(file)\n",
    "\n",
    "    # Remove timestamp column, assuming it's named 'timestamp' as a placeholder\n",
    "    df = df.drop(columns=['timestamp']) if 'timestamp' in df.columns else df\n",
    "\n",
    "    # Add the extracted yolomodel as a new column\n",
    "    df['yolomodel'] = yolomodel\n",
    "\n",
    "    # Append to the list of DataFrames\n",
    "    dataframes.append(df)\n",
    "    remaining -= 1\n",
    "    if remaining == 0:\n",
    "        break\n",
    "\n",
    "# Determine and print the columns of each DataFrame\n",
    "# for idx, df in enumerate(dataframes):\n",
    "#     print(f\"Columns of DataFrame {idx}: {df.columns.tolist()}\")\n",
    "\n",
    "# Determine the differences in columns among the DataFrames\n",
    "def print_column_differences(dfs):\n",
    "    all_columns = [set(df.columns) for df in dfs]\n",
    "    for i, cols in enumerate(all_columns):\n",
    "        differences = cols.difference(*[cols2 for j, cols2 in enumerate(all_columns) if j != i])\n",
    "        if differences:\n",
    "            print(f\"Differences for DataFrame {i}: {differences}\")\n",
    "\n",
    "print_column_differences(dataframes)\n",
    "\n",
    "# Determine common columns across all DataFrames\n",
    "common_columns = list(set.intersection(*(set(df.columns) for df in dataframes)))\n",
    "\n",
    "# Standardize each DataFrame to have only columns that are common across all DataFrames\n",
    "dataframes = [df[common_columns] for df in dataframes]\n",
    "\n",
    "# Combine all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "combined_df.to_feather(\"datasets/predict_yolomodel.feather\")\n"
   ],
   "id": "a9fd13de3e6e2b2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f\"Number of rows: {combined_df.shape[0]} and Number of columns: {combined_df.shape[1]}\")",
   "id": "8a506fa6bde8e454",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import Levenshtein\n",
    "\n",
    "# Define the target column as a JSON string\n",
    "target = '{\"__name__\": \"node_cpu_seconds_rate\", \"cpu\": \"0\", \"instance\": \"worker\", \"mode\": \"user\"}'\n",
    "\n",
    "# Initialize the directory path and the list to store filenames with no close match\n",
    "feather_directory = \"combined_data\"\n",
    "no_close_match_files = []\n",
    "\n",
    "# Loop through each feather file in the directory\n",
    "for file in glob.glob(f\"{feather_directory}/*.feather\"):\n",
    "    # Extract the base filename\n",
    "    filename = os.path.basename(file)\n",
    "\n",
    "    # Extract yolomodel from the filename\n",
    "    yolomodel = filename.split('_')[1]\n",
    "\n",
    "    # Read the dataframe\n",
    "    df = pd.read_feather(file)\n",
    "\n",
    "    # Check if the target is among the columns\n",
    "    if target not in df.columns:\n",
    "        closest_distance = float('inf')\n",
    "        closest_column = None\n",
    "        for col in df.columns:\n",
    "            json_col = json.loads(col)\n",
    "            # if json_col[\"__name__\"] == \"node_cpu_seconds_rate\":\n",
    "            dist = Levenshtein.distance(json.dumps(json_col), target)\n",
    "            if dist < closest_distance:\n",
    "                closest_distance = dist\n",
    "                closest_column = col\n",
    "\n",
    "        if closest_column:\n",
    "            print(f\"File: {file} - Closest column: {closest_column}\")\n",
    "        else:\n",
    "            no_close_match_files.append(file)\n",
    "\n",
    "# Optionally, print the files with no close matches\n",
    "if no_close_match_files:\n",
    "    print(\"Files with no close matches:\", no_close_match_files)\n",
    "# pip install python-Levenshtein"
   ],
   "id": "30b6fcca6e4c583c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3dcbf4926918183e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
