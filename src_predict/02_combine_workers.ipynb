{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Get all subdirs in \"preprocessed_workers\"\n",
    "base_dir = \"preprocessed_workers\"\n",
    "combined_dir = \"combined_data\"\n",
    "\n",
    "# Create 'combined_data' directory if it doesn't exist\n",
    "os.makedirs(combined_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over each subdirectory\n",
    "for subfolder in os.listdir(base_dir):\n",
    "    subfolder_path = os.path.join(base_dir, subfolder)\n",
    "\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # List to store DataFrames\n",
    "        data_frames = []\n",
    "\n",
    "        # Iterate over possible worker{id}.feather files\n",
    "        for worker_id in range(1, 6):\n",
    "            feather_file = f\"worker{worker_id}.feather\"\n",
    "            feather_path = os.path.join(subfolder_path, feather_file)\n",
    "            if os.path.exists(feather_path):\n",
    "                df = pd.read_feather(feather_path)\n",
    "                data_frames.append(df)\n",
    "\n",
    "        if data_frames:\n",
    "            # Find common columns across all DataFrames\n",
    "            common_columns = list(set(data_frames[0].columns))\n",
    "            for df in data_frames[1:]:\n",
    "                common_columns = list(set(common_columns).intersection(df.columns))\n",
    "\n",
    "            # Keep only common columns in each DataFrame\n",
    "            data_frames = [df[common_columns] for df in data_frames]\n",
    "\n",
    "            # Combine all data frames\n",
    "            combined_df = pd.concat(data_frames, ignore_index=True, axis=0)\n",
    "            # Save combined dataframe to \"combined_data\" directory\n",
    "            combined_feather_path = os.path.join(combined_dir, f\"{subfolder}.feather\")\n",
    "            combined_df.to_feather(combined_feather_path)\n",
    "            print(f\"Saved combined DataFrame to: {combined_feather_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get all subdirs in \"preprocessed_workers\"\n",
    "base_dir = \"preprocessed_workers\"\n",
    "combined_dir = \"combined_data\"\n",
    "\n",
    "# Create 'combined_data' directory if it doesn't exist\n",
    "os.makedirs(combined_dir, exist_ok=True)\n",
    "\n",
    "# To track the number of rows and columns for each combined DataFrame\n",
    "rows_columns_info = []\n",
    "\n",
    "# To track unique columns across all combined dataframes\n",
    "unique_columns_set = set()\n",
    "\n",
    "# Iterate over each subdirectory\n",
    "for subfolder in os.listdir(base_dir):\n",
    "    subfolder_path = os.path.join(base_dir, subfolder)\n",
    "\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # List to store DataFrames\n",
    "        data_frames = []\n",
    "\n",
    "        # Iterate over possible worker{id}.feather files\n",
    "        for worker_id in range(1, 6):\n",
    "            feather_file = f\"worker{worker_id}.feather\"\n",
    "            feather_path = os.path.join(subfolder_path, feather_file)\n",
    "            if os.path.exists(feather_path):\n",
    "                df = pd.read_feather(feather_path)\n",
    "                data_frames.append(df)\n",
    "\n",
    "        if data_frames:\n",
    "            # Find common columns across all DataFrames\n",
    "            common_columns = list(set(data_frames[0].columns))\n",
    "            for df in data_frames[1:]:\n",
    "                common_columns = list(set(common_columns).intersection(df.columns))\n",
    "\n",
    "            # Keep only common columns in each DataFrame\n",
    "            data_frames = [df[common_columns] for df in data_frames]\n",
    "\n",
    "            # Combine all data frames\n",
    "            combined_df = pd.concat(data_frames, ignore_index=True, axis=0)\n",
    "\n",
    "            # Save combined dataframe to \"combined_data\" directory\n",
    "            combined_feather_path = os.path.join(combined_dir, f\"{subfolder}.feather\")\n",
    "            combined_df.to_feather(combined_feather_path)\n",
    "            print(f\"Saved combined DataFrame to: {combined_feather_path}\")\n",
    "\n",
    "            # Record rows and columns of the combined DataFrame\n",
    "            rows_columns_info.append((subfolder, combined_df.shape[0], combined_df.shape[1]))\n",
    "\n",
    "            # Update unique columns set with columns from combined DataFrame\n",
    "            unique_columns_set.update(combined_df.columns)\n",
    "\n",
    "# Plot the number of rows and columns for each combined DataFrame\n",
    "if rows_columns_info:\n",
    "    df_info = pd.DataFrame(rows_columns_info, columns=[\"Combined DataFrame\", \"Rows\", \"Columns\"])\n",
    "    df_info.plot(x=\"Combined DataFrame\", y=[\"Rows\", \"Columns\"], kind=\"bar\", figsize=(10, 6))\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(\"Rows and Columns in Each Combined DataFrame\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Compute and display number of unique columns across all combined DataFrames\n",
    "num_unique_columns = len(unique_columns_set)\n",
    "print(f\"Number of unique columns across all combined DataFrames: {num_unique_columns}\")"
   ],
   "id": "9cc77533edd6f816",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
